{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai pypdf faiss-cpu"
      ],
      "metadata": {
        "id": "92zb-xt4Hwc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1832c39a-6efb-4762-e08a-686436e43226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.312-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pypdf\n",
            "  Downloading pypdf-3.16.4-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
            "  Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: faiss-cpu, pypdf, mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, openai, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.6.1 faiss-cpu-1.7.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.312 langsmith-0.0.43 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.28.1 pypdf-3.16.4 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "id": "bTJ6uS9LMBNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06a20373-0220-4bb7-87de-a636af386c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2"
      ],
      "metadata": {
        "id": "vPBEs3buDxYa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c83b0f-2a62-4617-9430-8365f79646d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V0tnturELFa",
        "outputId": "4934ead2-3570-4fe0-cb0d-db085dd176d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/AQG/DL.pdf'"
      ],
      "metadata": {
        "id": "NFSTMS5oE_A8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "\n",
        "# Specify the path to your PDF file\n",
        "pdf_path = '/content/drive/My Drive/AQG/DL.pdf'\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_file = open(pdf_path, 'rb')\n",
        "\n",
        "# Create a PDF reader object\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "\n",
        "# Read text from the first page\n",
        "\n",
        "page = pdf_reader.pages[0]\n",
        "text = page.extract_text()\n",
        "\n",
        "# Close the PDF file\n",
        "pdf_file.close()\n",
        "\n",
        "# Print the extracted text\n",
        "print(text)"
      ],
      "metadata": {
        "id": "bUzdK7QvFCvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41a02b3-4be2-4a2f-c70d-3d85c575ba26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Learning  \n",
            "with Applications \n",
            "Using Python\n",
            "Chatbots and Face, Object, and Speech \n",
            "Recognition With TensorFlow and Keras\n",
            "—\n",
            "Navin Kumar Manaswi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
        "\n",
        "# Specify the path to your PDF file\n",
        "pdf_path = '/content/drive/My Drive/AQG/DL.pdf'\n",
        "\n",
        "# Open the PDF file and extract text\n",
        "pdf_file_obj = open(pdf_path, 'rb')\n",
        "pdf_reader = PyPDF2.PdfReader(pdf_file_obj)  # Use PdfReader instead of PdfFileReader\n",
        "num_pages = len(pdf_reader.pages)  # Get the number of pages\n",
        "\n",
        "detected_text = ''\n",
        "\n",
        "for page_num in range(num_pages):\n",
        "    page = pdf_reader.pages[page_num]\n",
        "    detected_text += page.extract_text() + '\\n\\n'\n",
        "\n",
        "pdf_file_obj.close()\n",
        "\n",
        "# Set your OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = '....'\n",
        "\n",
        "# Split the extracted text into documents\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "texts = text_splitter.create_documents([detected_text])\n",
        "\n",
        "# Create an index store for the text\n",
        "directory = 'index_store'\n",
        "vector_index = FAISS.from_documents(texts, OpenAIEmbeddings())\n",
        "vector_index.save_local(directory)\n",
        "\n",
        "# Load the index\n",
        "vector_index = FAISS.load_local('index_store', OpenAIEmbeddings())\n",
        "retriever = vector_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
        "\n",
        "# Create a question generation interface\n",
        "qa_interface = RetrievalQA.from_chain_type(llm=ChatOpenAI(), chain_type=\"stuff\",\n",
        "                                           retriever=retriever, return_source_documents=True)\n",
        "\n",
        "# Generate questions based on the provided topic\n",
        "response = qa_interface(\"\"\"\n",
        "list 2 questions having 4 multiple choice answer having\n",
        "varying difficulty and weightage based on the topic \"Deep learning\"\n",
        "\"\"\")\n",
        "\n",
        "# Print the generated questions\n",
        "print(response['result'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLDWqBksLHag",
        "outputId": "54483cb8-866b-4c1c-ebe7-54f9d4a6a54e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Which of the following is a commonly used image dataset in deep learning?\n",
            "a) MNIST\n",
            "b) CIFAR-10\n",
            "c) ImageNet\n",
            "d) MS COCO\n",
            "\n",
            "2. What are the four core parts of deep learning models in Keras?\n",
            "a) Data loading, model evaluation, preprocessing, prediction\n",
            "b) Model definition, model compilation, model fitting, making predictions\n",
            "c) Data preprocessing, model training, model evaluation, data prediction\n",
            "d) Model definition, data preprocessing, model fitting, model evaluation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate questions based on the provided topic\n",
        "response = qa_interface(\"\"\"\n",
        "List the answers for the generated questions\n",
        "\"\"\")\n",
        "\n",
        "# Print the generated questions\n",
        "print(response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmnG-zvkGJQO",
        "outputId": "a877737b-efd3-42be-c860-74f94ca3cdf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't have access to the specific answers for the generated questions as they are not mentioned in the given context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate questions based on the provided topic\n",
        "response = qa_interface(\"\"\"\n",
        "list 2 questions with multiple choice answer having\n",
        "varying difficulty and weightage based on the topic \"Deep learning\"\n",
        "\"\"\")\n",
        "\n",
        "# Print the generated questions\n",
        "print(response['result'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgFKcwX2OG-Y",
        "outputId": "c39c946a-fc9f-4ebe-cf98-6da964ff57be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Question: What is the concept of deep learning and how does it differ from traditional machine learning techniques? (4 marks)\n",
            "\n",
            "Answer: Deep learning is a subfield of machine learning that focuses on using artificial neural networks with multiple layers to model and understand complex patterns in data. Unlike traditional machine learning techniques, deep learning algorithms can automatically learn hierarchical representations of data by progressively extracting higher-level features from raw input. This allows deep learning models to achieve state-of-the-art performance in various tasks such as image recognition, speech recognition, and natural language processing.\n",
            "\n",
            "2. Question: Explain the architecture and working of a convolutional neural network (CNN). Provide an example of a real-world application where CNNs are used. (6 marks)\n",
            "\n",
            "Answer: A convolutional neural network (CNN) is a deep learning architecture specifically designed for image and visual recognition tasks. It consists of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers apply a set of learnable filters to the input image, extracting local features and capturing spatial relationships. The pooling layers downsample the feature maps, reducing the dimensionality and providing translation invariance. The fully connected layers perform the final classification based on the extracted features.\n",
            "\n",
            "One real-world application of CNNs is in autonomous vehicles. CNNs can be used to detect and recognize objects in the environment, such as pedestrians, vehicles, and traffic signs. This enables the vehicle to make informed decisions and take appropriate actions based on the detected objects.\n",
            "\n",
            "3. Question: Explain the concept of recurrent neural networks (RNNs) and their significance in sequential data analysis. Provide an example of a task where RNNs are commonly used. (5 marks)\n",
            "\n",
            "Answer: Recurrent neural networks (RNNs) are a type of deep learning model that is specifically designed to handle sequential data, such as time series, text, and speech. Unlike feedforward neural networks, RNNs have feedback connections that allow them to maintain internal memory and process inputs in a sequential manner. This enables RNNs to capture long-term dependencies and context information in sequential data.\n",
            "\n",
            "One common task where RNNs are used is in natural language processing, specifically in language modeling and text generation. RNNs can learn the underlying structure and patterns in a text corpus, allowing them to generate coherent and contextually relevant sentences or paragraphs based on a given input prompt.\n",
            "\n",
            "4. Question: Discuss the concept of transfer learning in deep learning and its advantages. Provide an example of a pre-trained model that is commonly used for transfer learning. (3 marks)\n",
            "\n",
            "Answer: Transfer learning is a technique in deep learning where knowledge gained from training a model on one task is leveraged to improve the performance on a different but related task. Instead of training a model from scratch, transfer learning allows us to use pre-trained models that have been trained on large datasets for tasks like image classification or object detection.\n",
            "\n",
            "One commonly used pre-trained model for transfer learning is the VGG (Visual Geometry Group) model. It has been trained on the ImageNet dataset, which contains millions of labeled images from various categories. By using the pre-trained VGG model as a feature extractor, we can achieve good performance on tasks like image classification even with limited training data for the specific task.\n",
            "\n",
            "5. Question: Discuss the challenges and limitations of deep learning. Provide an example of a scenario where deep learning might not be the best approach. (2 marks)\n",
            "\n",
            "Answer: Deep learning has several challenges and limitations. One challenge is the requirement of a large amount of labeled training data. Deep learning models typically require a significant amount of diverse and accurately labeled data to learn meaningful representations. Acquiring and labeling such data can be time-consuming and expensive.\n",
            "\n",
            "Another limitation is the computational resource requirement. Training deep learning models can be computationally intensive, especially for large-scale models with millions of parameters. This requires powerful hardware, such as GPUs, and can be a barrier for individuals or organizations with limited resources.\n",
            "\n",
            "An example scenario where deep learning might not be the best approach is when the available data is limited or the problem is relatively simple. If the dataset is small or the problem can be effectively solved using traditional machine learning techniques, it might be more efficient and practical to use simpler models that require less computational resources and labeled data.\n"
          ]
        }
      ]
    }
  ]
}
